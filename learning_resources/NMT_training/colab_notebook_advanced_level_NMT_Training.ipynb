{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![KeyVisual_DataLitMT - Kopie.jpg](data:image/jpeg;base64,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)\n",
        "\n",
        "# Data Processing: NMT Training Notebook – Advanced Level\n",
        "**How to train an NMT model from scratch**"
      ],
      "metadata": {
        "id": "krf32FwJyk5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE: Training an NMT model takes a long time. We advise that you only work through this notebook if you have about TWO HOURS of time to spare.** This is already a very short training time and can only be achieved when training a rather small model. Big NMT models are usually trained over a number of days."
      ],
      "metadata": {
        "id": "anRPeyxmQsXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Colab Notebook covers the sub-dimensions of *Data Processing* (and, to some extent, *Data Creation*) of the [DataLit<sup>MT</sup> Competence Matrix](https://itmk.github.io/The-DataLitMT-Project/matrix/). This notebook guides you step-by-step through accessing previously prepared data to train a neural machine translation (NMT) model using the [OpenNMT-py toolkit](https://opennmt.net/). Training an NMT model is part of *Technical MT Literacy*, as illustrated in the [Professional Machine Translation Literacy Framework](https://itmk.github.io/The-DataLitMT-Project/framework/#professional-mt-literacy). In this notebook, we use the *Transformer* architecture, which was proposed by [Vaswani et al. (2017)](https://papers.nips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)). The Transformer has become not only the standard architecture for high-performing NMT systems, but also for large language models such as [Google's BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) or [OpenAI's GPT models](https://openai.com/api/). If you would like to know more about how the Transformer architecture works, check out Jay Alammar's excellent article on [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/).\n",
        "\n",
        "Note: Before you work through this notebook, we recommend that you complete the Data Planning and Collection (data preparation) task first, either at [Basic Level](https://colab.research.google.com/drive/17aCfPF0Zw80gW0FYg_iRo16YVSMAaNKG?usp=sharing) or at [Advanced Level](https://colab.research.google.com/drive/1ls2DIKkD8B2FgkIEYZVjqpAVcr5IZMRa?usp=sharing) and to *save* the datasets created in this task in your Google Drive folder. If you would like to skip this step and start training your NMT model right away, check the *Accessing Data* step below.\n",
        "\n",
        "**General Information**\n",
        "There are a number of open-source frameworks for training an NMT model from scratch, such as [JoeyNMT](https://joeynmt.readthedocs.io/en/latest/) or OpenNMT-py. A comprehensive list of frameworks and pre-trained models can be found, for example, on [Hugging Face](https://huggingface.co/). The code used in this notebook is provided by OpenNMT-py. While it may seem quite complex at first, implementing this code and adjusting relevant parameters is actually rather straightforward. All steps performed in this notebook will be described in detail both here in this notebook and in the accompanying tutorial video. We recommend that you watch the video to get a good overview and a thorough understanding of the process of training an NMT model from scratch.\n",
        "\n",
        "**Steps to take**\n",
        "For this MT project scenario, we chose the English-German parallel dataset TED2020, with English being the source and German the target language, as illustrated in our [Basic](https://colab.research.google.com/drive/17aCfPF0Zw80gW0FYg_iRo16YVSMAaNKG?usp=sharing) and [Advanced](https://colab.research.google.com/drive/1ls2DIKkD8B2FgkIEYZVjqpAVcr5IZMRa?usp=sharing) notebooks on Data Planning and Data Collection. As mentioned above, completing one of the the Data Preparation notebooks is a recommended preparatory step for the present notebook, since it will give you a good understanding of how we arrived at the training data to be used in the present notebook. In the Data Preparation notebook, we guide you through downloading the required NMT training data, preparing (cleaned and filtered) and subwording this data, and splitting it into three sub-datasets (training, development and test), which are needed for NMT training. In the present notebook, you will learn how to train an NMT engine from scratch using your three sub-datasets and how to use your NMT model to translate texts. Here, we will use English as the source and German as the target language, but you could also use your dataset to train a German-English NMT model. Of course, if you have a different dataset at hand and know how to access it and implement it here, you are welcome to train an NMT model using this dataset instead."
      ],
      "metadata": {
        "id": "JsfG8UrPzKxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional – Accessing Data\n",
        "\n",
        "If you did not complete the previous task on Data Preparation and would like to start training your own NMT model right away, you can access and download all data required for this notebook on our GitHub repository [here](https://github.com/ITMK/DataLitMT/blob/main/learning_resources/NMT_training/TED_data.zip) (the file is called *TED data.zip*). This zip file contains all datasets required for training an NMT in this notebook as well as the subword models needed for desubwording texts translated with our model (described at the end of notebook). Unzip the file and save the data (without re-naming the files) in a folder on your Google Drive. Then you can refer to this Drive folder in this notebook and follow the code. This step is also shown in the tutorial video."
      ],
      "metadata": {
        "id": "SH63iJzvWfas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 Housekeeping\n",
        "\n",
        "For this notebook, it is required that you **change your runtime to GPU**. All Colab Notebooks run on CPU by default. Since we'll be needing more computing power to train an NMT model than can be provided by a CPU, we use the more powerful GPU which Google Colab provides for such use cases.\n",
        "To switch from CPU to GPU, go to \"runtime\", and then --> \"change runtime\". For \"hardware accelerator\" select GPU.\n"
      ],
      "metadata": {
        "id": "MoPiSKJi3ZdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing OpenNMT-py\n",
        "\n",
        "First, you need to install the OpenNMT-py package – the most recent version is version 3.0. Simply run the following cell to do so. OpenNMT requires Python 3.7 or above (which should be installed in this Colab environment). For more information on [OpenNMT-py](https://opennmt.net/OpenNMT-py/) and how to use it, have a look at their [GitHub](https://github.com/OpenNMT/OpenNMT-py) or check out the [official documentation](https://opennmt.net/OpenNMT-py/) or the [forum](https://forum.opennmt.net/)."
      ],
      "metadata": {
        "id": "A-c_8DEp8s6l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSUyCs23M_H2"
      },
      "outputs": [],
      "source": [
        "!pip3 install OpenNMT-py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting to Google Drive to Access Datasets\n",
        "\n",
        "Next, you will need to connect this notebook to your Google Drive account in order to then access the datasets that you have previously prepared and saved. To connect this notebook to Google Drive, run the cell below. You will need to select and confirm your Google Account. This step is also shown in the tutorial video.\n",
        "\n",
        "If connecting to Google Drive was successful, the cell below will output “Drive Mounted”  or a similar message."
      ],
      "metadata": {
        "id": "PvtOqyl_8vPq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z-KkNDLtCL1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhgIdJn-cLqu"
      },
      "source": [
        "The following step is **important** and you **actively need to change the line of code in the code cell below** to access the folder in your Google Drive where you have previously saved the datasets from the Data Planning and Collection task. In the code below, replace the string \"YOUR_FOLDER_NAME\" (likely called *MT_data_preparation* from the data preparation task) with the folder that contains your datasets.\n",
        "\n",
        "If you have done so, run the cell below in order to change the current directory to that folder. This means that you can directly access the data saved in that folder throughout this notebook and you can also save new data directly to that folder. The code cell below will also list the content of your folder. This way, you can make sure that you are actually connected to the correct folder.\n",
        "\n",
        "Your folder should contain the following datasets from the Data Preparation task (the files should be listed after running the cell below):\n",
        "\n",
        "*   `TED2020.de-en.de-filtered.de.subword.dev`\n",
        "*   `TED2020.de-en.de-filtered.de.subword.test`\n",
        "*   `TED2020.de-en.de-filtered.de.subword.train`\n",
        "*   `TED2020.de-en.en-filtered.en.subword.dev`\n",
        "*   `TED2020.de-en.en-filtered.en.subword.test`\n",
        "*   `TED2020.de-en.en-filtered.en.subword.train`\n",
        "\n",
        "**Important:** For the following steps, your datasets must be named **exactly** as described here. If not, please re-name your datasets in your Google Drive folder to match the file names used in this notebook. The file names are rather long, but to make sure that the correct files are referred to, please do not rename them (unless you are confident to do so and know how to change the names in all relevant code cells in this notebook)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWVOWYedzZ_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c301aca7-f2e6-4cd1-f648-cd75a015e846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MT_data_preparation\n",
            "source.model\n",
            "target.model\n",
            "TED2020.de-en.de-filtered.de.subword.dev\n",
            "TED2020.de-en.de-filtered.de.subword.test\n",
            "TED2020.de-en.de-filtered.de.subword.train\n",
            "TED2020.de-en.en-filtered.en.subword.dev\n",
            "TED2020.de-en.en-filtered.en.subword.test\n",
            "TED2020.de-en.en-filtered.en.subword.train\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/MT_data_preparation/\n",
        "!ls\n",
        "\n",
        "# If you have saved your data in an 'MT_data_preparation' folder, the code line above would be: %cd /content/drive/MyDrive/MT_data_preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Creating the Training Configuration File\n",
        "\n",
        "Before you work through this step, make sure that the previous steps have been completed and that you have connected this notebook to your Google Drive folder. The cell below is the first crucial step towards training an NMT model. It creates a configuration file that contains all information needed to train an NMT model. The cell below defines a Transformer NMT model and the code is provided by OpenNMT, as described above.\n",
        "\n",
        "It is **important** to note that the parameters used in the code cell below have been adjusted to allow for a quick NMT training. Parameters can be adjusted individually for NMT model training, very much depending on what the training focus should be. Have a look at the [OpenNMT-py training parameters](https://opennmt.net/OpenNMT-py/options/train.html) if you want to know more about the individual parameters. A list of (optional/extensive) parameters for the Tensorflow implementation OpenNMT-tf, many of which can also be used for the Python implementation OpenNMT-py, can be found [here](https://opennmt.net/OpenNMT-tf/configuration.html)."
      ],
      "metadata": {
        "id": "cZicwEXbNFqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "SiaPaVfXWynj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPlmhd426B7l"
      },
      "source": [
        "Let's have a more detailed look at the parameters defined below. Please **do not** change anything in the code unless you are confident to do so. It is **not required** to change the code below at this point, you can simply run the cell as it is. We will, however, explain relevant aspects of these parameters here. Again, make sure that your datasets are named **exactly** as described above, since we refer to those datasets by their names in the code below.\n",
        "\n",
        "* `config.yaml` – The first line creates a configuration file in [yaml](https://yaml.org/spec/1.2.2/) format. It will be saved as *config.yaml* in your Drive folder. This file is needed for NMT training later, as it contains all the information required for defining and training your NMT model!\n",
        "* `save_data: run` – This indicates that the vocabulary data (created later) will be saved in a folder called *run* in your Drive folder.\n",
        "* `data` --> `corpus_1` --> `path_src:` –  Here, the path to the source training data in your Drive folder is defined.\n",
        "* `data` --> `corpus_1` --> `path_tgt:` – Here, the path to the target training data in your Drive folder is defined.\n",
        "* `data` --> `valid` --> `path_src:` – Here, the path to the source development (often also called validation) data in your Drive folder is defined.\n",
        "* `data` --> `valid` --> `path_tgt:` –  Here, the path to the target development data in your Drive folder is defined.\n",
        "* `source_vocab: run/source.vocab` – This indicates that the source vocabulary data (created later) will be saved in the *run* folder in your Drive folder.\n",
        "* `target_vocab: run/target.vocab` – This indicates that the target vocabulary data (created later) will be saved in the *run* folder in your Drive folder.\n",
        "* `source_vocab_size` and `target_vocab_size` – This parameter is set to **50k** words, meaning that we use a source and target vocabulary of 50,000 words each.\n",
        "* `tokenization options` – The input data could be tokenized, which is advised for NMT model training. This parameter refers to the subwording `source.model` and `target.model` that we created in the data preparation task.\n",
        "* `log_file: train.log` – At the end of the NMT training process, this *train.log* file will also be saved to your Drive folder. It logs all training steps and provides further information on model training.\n",
        "* `save_model: models/model.fren` – The NMT models trained here will be saved into a separate *models* folder in your Drive folder. They will automatically be named *model.fren_step_1000.pt* and so forth, for each training step. The **final** model (in this case *model.fren_step_4000.pt*, since we use 4,000 training steps as defined below) will then be used to translate the test dataset.\n",
        "* `save_checkpoint_steps` – This parameter defines how frequently a model is saved. We set it to **1000**, meaning that a model is saved every thousand steps. \n",
        "* `keep_checkpoint` – This defines how many of the saved checkpoints will be kept (the latest ones). Trained models take up quite some space, so model checkpoints saved in-between are not needed for final translation but can be kept as a backup or in case the training crashes before it ends. Here we keep 4 checkpoints (i.e., all checkpoints which are created in our training scenario).\n",
        "* `train_steps` – This defines the training steps for NMT model training. This value is usually set above 100,000 but for a quick tutorial using a small dataset (as in our notebook), we can set this value to **4000** – which will still result in an acceptable translation quality.\n",
        "* `valid_steps` – This parameter defines how frequently the training data is validated. For this step, the development dataset is used. Here we define validation to take place every **1000** steps. So, a total of four times in our scenario.\n",
        "* `gpu_ranks = [0]` – A GPU rank of [0] shows that 1 GPU is used (most programming languages start counting from 0). As mentioned above, a GPU (which provides more computing power than a CPU) is needed for NMT training.\n",
        "* `learning_rate` – This parameter is set to 1 here. 1 is a high value for the learning rate but allows for quicker training, as is our aim in this notebook.Change value for larger datasets and longer training times as specified below.\n",
        "\n",
        "-------------------------------------------------------------------------------\n",
        "Not necessary here, but recommended for **larger datasets** (with millions of sentences): \n",
        "* `source_vocab_size` and `target_vocab_size` – This parameter can be set to anywhere between 32k and 100k.\n",
        "* `train_steps` – 100k-200k or more\n",
        "* `valid_steps` – Can be 10,000 if the train steps are big enough\n",
        "* `warmup_steps` – Potentially 4000 or 8000\n",
        "* `save_checkpoint_steps` – (depends on how frequently you want to save checkpoints. Often same value as valid_steps, or more)\n",
        "* `keep_checkpoint` – (depends on how many saved checkpoints you want to keep – 10 or more)\n",
        "* `learning_rate` – For larger datasets and longer training times, change this value to as low as 0.0002. Otherwise, the model will learn fast but then stall or even drop back to zero in terms of accuracy.\n",
        "\n",
        "These parameters are discussed in a little more detail in the tutorial video."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Config File\n",
        "\n",
        "Without further ado, you can now run the cell below to create your `config.yaml` file and load it into your Google Drive folder.\n",
        "\n",
        "**NOTE: This step is only done once! If you have made a mistake, delete the created `config.yaml` file and run the cell again.**"
      ],
      "metadata": {
        "id": "XnlZFI5XNNAU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbW7Xek6UDlY"
      },
      "outputs": [],
      "source": [
        "# Create the config file\n",
        "\n",
        "config = '''# config.yaml\n",
        "\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: run\n",
        "\n",
        "# Training files\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: TED2020.de-en.en-filtered.en.subword.train\n",
        "        path_tgt: TED2020.de-en.de-filtered.de.subword.train\n",
        "        transforms: [filtertoolong]\n",
        "    valid:\n",
        "        path_src: TED2020.de-en.en-filtered.en.subword.dev\n",
        "        path_tgt: TED2020.de-en.de-filtered.de.subword.dev\n",
        "        transforms: [filtertoolong]\n",
        "\n",
        "# Vocabulary files, generated by onmt_build_vocab\n",
        "src_vocab: run/source.vocab\n",
        "tgt_vocab: run/target.vocab\n",
        "\n",
        "# Vocabulary size – should be the same as in SentencePiece\n",
        "src_vocab_size: 50000\n",
        "tgt_vocab_size: 50000\n",
        "\n",
        "# Filter out source/target longer than n if [filtertoolong] enabled\n",
        "src_seq_length: 150\n",
        "src_seq_length: 150\n",
        "\n",
        "# Tokenization options\n",
        "src_subword_model: source.model\n",
        "tgt_subword_model: target.model\n",
        "\n",
        "# Where to save the log file and the output models/checkpoints\n",
        "log_file: train.log\n",
        "save_model: models/model.fren\n",
        "\n",
        "# Stop training if it does not improve after n validations\n",
        "early_stopping: 10\n",
        "\n",
        "# Default: 5000 – Save a model checkpoint for each n\n",
        "save_checkpoint_steps: 1000\n",
        "\n",
        "# To save space, limit checkpoints to last n\n",
        "keep_checkpoint: 4\n",
        "\n",
        "seed: 3435\n",
        "\n",
        "# Default: 100000 – Train the model to max n steps \n",
        "# Increase to 200000 or more for large datasets\n",
        "# For fine-tuning, add up the required steps to the original steps\n",
        "train_steps: 4000\n",
        "\n",
        "# Default: 10000 – Run validation after n steps\n",
        "valid_steps: 1000\n",
        "\n",
        "# Default: 4000 – for large datasets, try up to 8000\n",
        "warmup_steps: 1000\n",
        "report_every: 100\n",
        "\n",
        "# Number of GPUs, and IDs of GPUs\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Batching\n",
        "bucket_size: 262144\n",
        "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
        "valid_batch_size: 2048\n",
        "max_generator_batches: 2\n",
        "accum_count: [4]\n",
        "accum_steps: [0]\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"fp16\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 1 # 0.002\n",
        "# warmup_steps: 8000\n",
        "decay_method: \"noam\"\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0\n",
        "param_init_glorot: true\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "position_encoding: true\n",
        "enc_layers: 6\n",
        "dec_layers: 6\n",
        "heads: 8\n",
        "hidden_size: 512\n",
        "word_vec_size: 512\n",
        "transformer_ff: 2048\n",
        "dropout_steps: [0]\n",
        "dropout: [0.1]\n",
        "attention_dropout: [0.1]\n",
        "'''\n",
        "\n",
        "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
        "  config_yaml.write(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to have a look at your Google Drive folder and check whether a *config.yaml* file has indeed been created. It might take a few moments to load."
      ],
      "metadata": {
        "id": "rfZkw1BANdj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the content of your folder\n",
        "!ls"
      ],
      "metadata": {
        "id": "c6DFpaLdNprO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a8c955-56fe-4d74-8660-31b39825ff72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.yaml\n",
            "run\n",
            "source.model\n",
            "target.model\n",
            "TED2020.de-en.de-filtered.de.subword.dev\n",
            "TED2020.de-en.de-filtered.de.subword.test\n",
            "TED2020.de-en.de-filtered.de.subword.train\n",
            "TED2020.de-en.en-filtered.en.subword.dev\n",
            "TED2020.de-en.en-filtered.en.subword.test\n",
            "TED2020.de-en.en-filtered.en.subword.train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0bcqYkEXhRY"
      },
      "source": [
        "# Building the Vocabulary\n",
        "\n",
        "Running the following cell will create your vocabulary. This creates two vocabulary files in your *run* folder, one for the source data and one for the target data (each containing 50k words, as defined in our *config.yaml* file above). You need to make sure that your configuration file is actually saved in your Drive folder, because the following cell refers to this file (*config.yaml*). Simply run the cell below.\n",
        "\n",
        "**NOTE: This step is only done once! If you have made a mistake, delete the created *run* folder and the source and target vocabulary files and run the cell again.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2GV1PgyUsJr",
        "outputId": "e4c2198e-feba-427d-9b51-00e2ea0a35ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2023-02-16 08:46:11,818 INFO] Counter vocab from -1 samples.\n",
            "[2023-02-16 08:46:11,818 INFO] n_sample=-1: Build vocab on full datasets.\n",
            "[2023-02-16 08:46:16,188 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=44)\n",
            "\n",
            "[2023-02-16 08:46:16,827 INFO] * Transform statistics for corpus_1(50.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=42)\n",
            "\n",
            "[2023-02-16 08:46:16,934 INFO] Counters src:48304\n",
            "[2023-02-16 08:46:16,934 INFO] Counters tgt:49993\n"
          ]
        }
      ],
      "source": [
        "# Build your vocabulary\n",
        "!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Have a look at the *run* sub-folder in your Google Drive folder to check whether a *source.vocab* and a *target.vocab* file have been created. It might take a moment to load.\n",
        "\n",
        "**Checking the Vocabulary Files** \n",
        "\n",
        "It is always good practice to check your files in between steps to make sure that everything has worked well. Run the cell below to print the first and last five vocabulary entries of the source and target vocabulary files."
      ],
      "metadata": {
        "id": "Oy2Y6LgqOxPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First 5 vocabulary entries:\")\n",
        "!head -n 5 'run/source.vocab' && echo \"----\" && head -n 5 'run/target.vocab'\n",
        "print()\n",
        "print(\"Last 5 vocabulary entries:\")\n",
        "!tail -n 5 'run/source.vocab' && echo \"-----\" && tail -n 5 'run/target.vocab'"
      ],
      "metadata": {
        "id": "XK1Mz2H290AS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c67a187-746f-435c-d80f-c05eead836aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 vocabulary entries:\n",
            ",\t257646\n",
            ".\t207678\n",
            "▁the\t166028\n",
            "▁to\t106896\n",
            "'\t101288\n",
            "----\n",
            ",\t300765\n",
            ".\t222474\n",
            "▁die\t90405\n",
            "▁und\t83564\n",
            "▁der\t59208\n",
            "\n",
            "Last 5 vocabulary entries:\n",
            "inventor\t1\n",
            "▁Paperfuge\t1\n",
            "▁igloo\t1\n",
            "Genes\t1\n",
            "injured\t1\n",
            "-----\n",
            "zuschlafen\t1\n",
            "▁auszuradieren\t1\n",
            "▁kultige\t1\n",
            "▁Poliomyelitis\t1\n",
            "Deshalb\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aCxETSnXcL-"
      },
      "source": [
        "# Training\n",
        "\n",
        "Congratulations on creating the configuration and the vocabulary files! You are now ready to train your own NMT model from scratch! 🎉\n",
        "\n",
        "Once again, make sure that the configuration file is saved in your original folder under **`config.yaml`**, and the vocabulary files are saved in the *run* folder as `source.vocab` and `target.vocab`.\n",
        "\n",
        "You can now simply run the cell below and your models will start loading! This step will take around **ONE HOUR** (which means it's coffee time for you). During this time, your computer must **remain on**, it cannot go into standby mode! This is very important. If the computer goes into standby mode or if you close this window, the training **will stop** and you would need to start again.\n",
        "\n",
        "**NOTE: This step is only done once! If you have made a mistake, delete the created models folder (and model files in that folder) and the train-log file (if already created) and run the cell again.**\n",
        "\n",
        "**Alternatively, save the previously created files and models in a separate folder (named differently) and run through the process again.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Explained"
      ],
      "metadata": {
        "id": "jQV951aAW4_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model training is explained in more detail in the tutorial video. Here is just a brief summary of interesting aspects to consider:\n",
        "* `Step 100/4000` – This indicates the first 100 training steps of a total of 4000. Each subsequent training step will be printed. The model training ends after it has completed `Step 4000/4000`, after the final validation has been done and the final checkpoint (*model.fren_step_4000.pt*) has been saved.\n",
        "* `acc` – This refers to the **accuracy** of the NMT model (the higher the accuracy, the higher the model quality). Accuracy starts at a very low value and increases as the training progresses. The idea is to get as high an accuracy value as possible. For longer training times, the accuracy might stall, at which point there is no further improvement (risk of [overfitting](https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/)) and the training should be stopped.\n",
        "* `xent` – This refers to the **cross entropy** (which indicates the gap between the actual and the desired state of the model i.e., the lower the cross entropy, the higher the model quality). Cross entropy decreases as the training progresses. Ideally, we want this value to be as close to zero as possible. In our present NMT trainings scenario, the value will likely remain at a value of 2.something."
      ],
      "metadata": {
        "id": "03vqJ2mKSPq1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the NMT Model\n",
        "\n",
        "Run the code cell below to start training your NMT model."
      ],
      "metadata": {
        "id": "YmBGqFR4W8W_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prJCKA2CP-dl",
        "outputId": "5840650d-f7ad-4efa-d2aa-a13f35072a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-02-16 08:52:00,556 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2023-02-16 08:52:00,557 INFO] Parsed 2 corpora from -data.\n",
            "[2023-02-16 08:52:00,558 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2023-02-16 08:52:00,834 INFO] Building model...\n",
            "[2023-02-16 08:52:06,480 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(48312, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(50000, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=512, out_features=50000, bias=True)\n",
            ")\n",
            "[2023-02-16 08:52:06,489 INFO] encoder: 43638784\n",
            "[2023-02-16 08:52:06,489 INFO] decoder: 76450640\n",
            "[2023-02-16 08:52:06,490 INFO] * number of parameters: 120089424\n",
            "[2023-02-16 08:52:06,490 INFO]  * src vocab size = 48312\n",
            "[2023-02-16 08:52:06,490 INFO]  * tgt vocab size = 50000\n",
            "[2023-02-16 08:52:06,495 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2023-02-16 08:52:06,495 INFO] Starting training on GPU: [0]\n",
            "[2023-02-16 08:52:06,495 INFO] Start training loop and validate every 1000 steps...\n",
            "[2023-02-16 08:52:06,496 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n",
            "[2023-02-16 08:52:11,633 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2023-02-16 08:53:47,412 INFO] Step 100/ 4000; acc: 6.4; ppl: 13207.7; xent: 9.5; lr: 0.00014; sents:   70439; bsz: 3731/3712/176; 14789/14713 tok/s;    101 sec;\n",
            "[2023-02-16 08:55:12,633 INFO] Step 200/ 4000; acc: 12.8; ppl: 1442.5; xent: 7.3; lr: 0.00028; sents:   64514; bsz: 3751/3720/161; 17606/17461 tok/s;    186 sec;\n",
            "[2023-02-16 08:56:38,998 INFO] Step 300/ 4000; acc: 16.8; ppl: 776.5; xent: 6.7; lr: 0.00042; sents:   72161; bsz: 3730/3708/180; 17276/17175 tok/s;    273 sec;\n",
            "[2023-02-16 08:57:53,082 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=104)\n",
            "\n",
            "[2023-02-16 08:57:53,082 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2023-02-16 08:58:30,323 INFO] Step 400/ 4000; acc: 19.7; ppl: 521.0; xent: 6.3; lr: 0.00056; sents:   69852; bsz: 3736/3711/175; 13425/13333 tok/s;    384 sec;\n",
            "[2023-02-16 08:59:57,371 INFO] Step 500/ 4000; acc: 25.1; ppl: 347.6; xent: 5.9; lr: 0.00070; sents:   69188; bsz: 3733/3706/173; 17154/17031 tok/s;    471 sec;\n",
            "[2023-02-16 09:01:24,758 INFO] Step 600/ 4000; acc: 31.1; ppl: 227.2; xent: 5.4; lr: 0.00084; sents:   71252; bsz: 3735/3711/178; 17098/16988 tok/s;    558 sec;\n",
            "[2023-02-16 09:02:52,021 INFO] Step 700/ 4000; acc: 35.5; ppl: 161.5; xent: 5.1; lr: 0.00098; sents:   67504; bsz: 3738/3711/169; 17137/17013 tok/s;    646 sec;\n",
            "[2023-02-16 09:03:43,377 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=100)\n",
            "\n",
            "[2023-02-16 09:03:43,377 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2023-02-16 09:04:40,196 INFO] Step 800/ 4000; acc: 40.5; ppl: 109.1; xent: 4.7; lr: 0.00112; sents:   69615; bsz: 3735/3714/174; 13813/13732 tok/s;    754 sec;\n",
            "[2023-02-16 09:06:07,290 INFO] Step 900/ 4000; acc: 43.9; ppl:  83.7; xent: 4.4; lr: 0.00126; sents:   69228; bsz: 3742/3711/173; 17185/17044 tok/s;    841 sec;\n",
            "[2023-02-16 09:07:34,719 INFO] Step 1000/ 4000; acc: 45.5; ppl:  73.8; xent: 4.3; lr: 0.00140; sents:   66892; bsz: 3747/3716/167; 17141/16999 tok/s;    928 sec;\n",
            "[2023-02-16 09:08:25,554 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 50.83389186859131 s.\n",
            "[2023-02-16 09:08:25,556 INFO] Train perplexity: 382.098\n",
            "[2023-02-16 09:08:25,556 INFO] Train accuracy: 27.7375\n",
            "[2023-02-16 09:08:25,556 INFO] Sentences processed: 690645\n",
            "[2023-02-16 09:08:25,556 INFO] Average bsz: 3738/3712/173\n",
            "[2023-02-16 09:08:25,556 INFO] Validation perplexity: 72.6565\n",
            "[2023-02-16 09:08:25,556 INFO] Validation accuracy: 46.8293\n",
            "[2023-02-16 09:08:25,557 INFO] Model is improving ppl: inf --> 72.6565.\n",
            "[2023-02-16 09:08:25,557 INFO] Model is improving acc: -inf --> 46.8293.\n",
            "[2023-02-16 09:08:25,594 INFO] Saving checkpoint models/model.fren_step_1000.pt\n",
            "[2023-02-16 09:09:58,222 INFO] Step 1100/ 4000; acc: 47.7; ppl:  63.2; xent: 4.1; lr: 0.00133; sents:   71051; bsz: 3727/3709/178; 10388/10337 tok/s;   1072 sec;\n",
            "[2023-02-16 09:10:29,191 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=109)\n",
            "\n",
            "[2023-02-16 09:10:29,191 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2023-02-16 09:11:49,885 INFO] Step 1200/ 4000; acc: 50.8; ppl:  48.1; xent: 3.9; lr: 0.00128; sents:   71706; bsz: 3727/3705/179; 13351/13271 tok/s;   1183 sec;\n",
            "[2023-02-16 09:13:16,930 INFO] Step 1300/ 4000; acc: 52.7; ppl:  42.0; xent: 3.7; lr: 0.00123; sents:   69495; bsz: 3734/3708/174; 17157/17040 tok/s;   1270 sec;\n",
            "[2023-02-16 09:14:43,965 INFO] Step 1400/ 4000; acc: 53.5; ppl:  39.9; xent: 3.7; lr: 0.00118; sents:   68609; bsz: 3739/3713/172; 17186/17066 tok/s;   1357 sec;\n",
            "[2023-02-16 09:16:11,271 INFO] Step 1500/ 4000; acc: 54.2; ppl:  37.9; xent: 3.6; lr: 0.00114; sents:   68777; bsz: 3740/3716/172; 17137/17025 tok/s;   1445 sec;\n",
            "[2023-02-16 09:16:18,814 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=102)\n",
            "\n",
            "[2023-02-16 09:16:18,814 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2023-02-16 09:16:27,417 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2023-02-16 09:18:03,408 INFO] Step 1600/ 4000; acc: 58.0; ppl:  28.6; xent: 3.4; lr: 0.00110; sents:   69881; bsz: 3738/3712/175; 13332/13242 tok/s;   1557 sec;\n",
            "[2023-02-16 09:19:30,735 INFO] Step 1700/ 4000; acc: 58.1; ppl:  28.6; xent: 3.4; lr: 0.00107; sents:   69243; bsz: 3735/3710/173; 17107/16994 tok/s;   1644 sec;\n",
            "[2023-02-16 09:20:57,991 INFO] Step 1800/ 4000; acc: 58.5; ppl:  27.9; xent: 3.3; lr: 0.00104; sents:   68627; bsz: 3737/3715/172; 17134/17032 tok/s;   1731 sec;\n",
            "[2023-02-16 09:22:17,957 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=105)\n",
            "\n",
            "[2023-02-16 09:22:17,957 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2023-02-16 09:22:47,782 INFO] Step 1900/ 4000; acc: 59.6; ppl:  26.3; xent: 3.3; lr: 0.00101; sents:   70932; bsz: 3735/3708/177; 13609/13509 tok/s;   1841 sec;\n",
            "[2023-02-16 09:24:14,769 INFO] Step 2000/ 4000; acc: 62.8; ppl:  21.4; xent: 3.1; lr: 0.00099; sents:   67918; bsz: 3744/3715/170; 17216/17081 tok/s;   1928 sec;\n",
            "[2023-02-16 09:24:15,290 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=9)\n",
            "\n",
            "[2023-02-16 09:25:03,411 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 48.63998794555664 s.\n",
            "[2023-02-16 09:25:03,413 INFO] Train perplexity: 115.043\n",
            "[2023-02-16 09:25:03,413 INFO] Train accuracy: 41.6649\n",
            "[2023-02-16 09:25:03,413 INFO] Sentences processed: 1.38688e+06\n",
            "[2023-02-16 09:25:03,413 INFO] Average bsz: 3737/3712/173\n",
            "[2023-02-16 09:25:03,413 INFO] Validation perplexity: 40.3044\n",
            "[2023-02-16 09:25:03,413 INFO] Validation accuracy: 55.5951\n",
            "[2023-02-16 09:25:03,413 INFO] Model is improving ppl: 72.6565 --> 40.3044.\n",
            "[2023-02-16 09:25:03,413 INFO] Model is improving acc: 46.8293 --> 55.5951.\n",
            "[2023-02-16 09:25:03,444 INFO] Saving checkpoint models/model.fren_step_2000.pt\n",
            "[2023-02-16 09:26:36,205 INFO] Step 2100/ 4000; acc: 62.2; ppl:  22.0; xent: 3.1; lr: 0.00096; sents:   68220; bsz: 3735/3714/171; 10564/10504 tok/s;   2070 sec;\n",
            "[2023-02-16 09:28:03,515 INFO] Step 2200/ 4000; acc: 62.6; ppl:  21.7; xent: 3.1; lr: 0.00094; sents:   70276; bsz: 3732/3711/176; 17096/17000 tok/s;   2157 sec;\n",
            "[2023-02-16 09:29:02,737 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=102)\n",
            "\n",
            "[2023-02-16 09:29:02,737 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2023-02-16 09:29:57,786 INFO] Step 2300/ 4000; acc: 64.2; ppl:  19.9; xent: 3.0; lr: 0.00092; sents:   70087; bsz: 3738/3713/175; 13084/12996 tok/s;   2271 sec;\n",
            "[2023-02-16 09:31:24,934 INFO] Step 2400/ 4000; acc: 66.3; ppl:  17.6; xent: 2.9; lr: 0.00090; sents:   68279; bsz: 3741/3714/171; 17172/17046 tok/s;   2358 sec;\n",
            "[2023-02-16 09:32:52,477 INFO] Step 2500/ 4000; acc: 65.8; ppl:  18.1; xent: 2.9; lr: 0.00088; sents:   71415; bsz: 3728/3706/179; 17033/16936 tok/s;   2446 sec;\n",
            "[2023-02-16 09:34:19,662 INFO] Step 2600/ 4000; acc: 65.8; ppl:  18.0; xent: 2.9; lr: 0.00087; sents:   70737; bsz: 3730/3707/177; 17113/17007 tok/s;   2533 sec;\n",
            "[2023-02-16 09:34:55,488 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=101)\n",
            "\n",
            "[2023-02-16 09:34:55,488 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2023-02-16 09:36:10,576 INFO] Step 2700/ 4000; acc: 68.3; ppl:  16.0; xent: 2.8; lr: 0.00085; sents:   68922; bsz: 3741/3712/172; 13492/13386 tok/s;   2644 sec;\n",
            "[2023-02-16 09:37:37,882 INFO] Step 2800/ 4000; acc: 69.4; ppl:  15.1; xent: 2.7; lr: 0.00084; sents:   69823; bsz: 3735/3715/175; 17114/17020 tok/s;   2731 sec;\n",
            "[2023-02-16 09:39:05,231 INFO] Step 2900/ 4000; acc: 68.5; ppl:  15.7; xent: 2.8; lr: 0.00082; sents:   66928; bsz: 3745/3712/167; 17151/17000 tok/s;   2819 sec;\n",
            "[2023-02-16 09:40:32,662 INFO] Step 3000/ 4000; acc: 68.6; ppl:  15.7; xent: 2.8; lr: 0.00081; sents:   69891; bsz: 3731/3706/175; 17068/16957 tok/s;   2906 sec;\n",
            "[2023-02-16 09:40:33,184 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=9)\n",
            "\n",
            "[2023-02-16 09:41:19,548 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 46.88481616973877 s.\n",
            "[2023-02-16 09:41:19,550 INFO] Train perplexity: 61.7953\n",
            "[2023-02-16 09:41:19,550 INFO] Train accuracy: 49.836\n",
            "[2023-02-16 09:41:19,550 INFO] Sentences processed: 2.08146e+06\n",
            "[2023-02-16 09:41:19,550 INFO] Average bsz: 3736/3711/173\n",
            "[2023-02-16 09:41:19,550 INFO] Validation perplexity: 38.4245\n",
            "[2023-02-16 09:41:19,550 INFO] Validation accuracy: 56.782\n",
            "[2023-02-16 09:41:19,550 INFO] Model is improving ppl: 40.3044 --> 38.4245.\n",
            "[2023-02-16 09:41:19,550 INFO] Model is improving acc: 55.5951 --> 56.782.\n",
            "[2023-02-16 09:41:19,582 INFO] Saving checkpoint models/model.fren_step_3000.pt\n",
            "[2023-02-16 09:41:42,317 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=110)\n",
            "\n",
            "[2023-02-16 09:41:42,318 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 11\n",
            "[2023-02-16 09:43:22,847 INFO] Step 3100/ 4000; acc: 71.7; ppl:  13.6; xent: 2.6; lr: 0.00079; sents:   66667; bsz: 3740/3714/167; 8791/8729 tok/s;   3076 sec;\n",
            "[2023-02-16 09:44:50,218 INFO] Step 3200/ 4000; acc: 71.8; ppl:  13.4; xent: 2.6; lr: 0.00078; sents:   71044; bsz: 3733/3710/178; 17091/16987 tok/s;   3164 sec;\n",
            "[2023-02-16 09:46:17,502 INFO] Step 3300/ 4000; acc: 71.3; ppl:  13.8; xent: 2.6; lr: 0.00077; sents:   69826; bsz: 3732/3709/175; 17105/16997 tok/s;   3251 sec;\n",
            "[2023-02-16 09:47:40,138 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=103)\n",
            "\n",
            "[2023-02-16 09:47:40,138 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 12\n",
            "[2023-02-16 09:47:46,344 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 13\n",
            "[2023-02-16 09:48:09,031 INFO] Step 3400/ 4000; acc: 71.1; ppl:  13.8; xent: 2.6; lr: 0.00076; sents:   69602; bsz: 3740/3715/174; 13414/13323 tok/s;   3363 sec;\n",
            "[2023-02-16 09:49:36,705 INFO] Step 3500/ 4000; acc: 74.4; ppl:  12.0; xent: 2.5; lr: 0.00075; sents:   68911; bsz: 3735/3711/172; 17041/16933 tok/s;   3450 sec;\n",
            "[2023-02-16 09:51:03,905 INFO] Step 3600/ 4000; acc: 74.0; ppl:  12.2; xent: 2.5; lr: 0.00074; sents:   68299; bsz: 3743/3716/171; 17169/17044 tok/s;   3537 sec;\n",
            "[2023-02-16 09:52:31,204 INFO] Step 3700/ 4000; acc: 73.8; ppl:  12.3; xent: 2.5; lr: 0.00073; sents:   72809; bsz: 3730/3708/182; 17091/16991 tok/s;   3625 sec;\n",
            "[2023-02-16 09:53:41,807 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=104)\n",
            "\n",
            "[2023-02-16 09:53:41,807 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 14\n",
            "[2023-02-16 09:54:26,340 INFO] Step 3800/ 4000; acc: 73.9; ppl:  12.2; xent: 2.5; lr: 0.00072; sents:   67059; bsz: 3735/3707/168; 12977/12880 tok/s;   3740 sec;\n",
            "[2023-02-16 09:55:53,862 INFO] Step 3900/ 4000; acc: 76.4; ppl:  11.0; xent: 2.4; lr: 0.00071; sents:   70753; bsz: 3731/3707/177; 17053/16941 tok/s;   3827 sec;\n",
            "[2023-02-16 09:57:21,156 INFO] Step 4000/ 4000; acc: 75.8; ppl:  11.3; xent: 2.4; lr: 0.00070; sents:   67275; bsz: 3734/3708/168; 17111/16993 tok/s;   3915 sec;\n",
            "[2023-02-16 09:57:21,716 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=9)\n",
            "\n",
            "[2023-02-16 09:58:08,029 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 46.871803283691406 s.\n",
            "[2023-02-16 09:58:08,031 INFO] Train perplexity: 41.4638\n",
            "[2023-02-16 09:58:08,031 INFO] Train accuracy: 55.73\n",
            "[2023-02-16 09:58:08,031 INFO] Sentences processed: 2.77371e+06\n",
            "[2023-02-16 09:58:08,031 INFO] Average bsz: 3736/3711/173\n",
            "[2023-02-16 09:58:08,031 INFO] Validation perplexity: 42.0468\n",
            "[2023-02-16 09:58:08,031 INFO] Validation accuracy: 56.6122\n",
            "[2023-02-16 09:58:08,031 INFO] Decreasing patience: 9/10\n",
            "[2023-02-16 09:58:08,062 INFO] Saving checkpoint models/model.fren_step_4000.pt\n"
          ]
        }
      ],
      "source": [
        "# Train the NMT model\n",
        "!onmt_train -config config.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations – you have trained your own NMT model!"
      ],
      "metadata": {
        "id": "KOI3xuEmAMop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation"
      ],
      "metadata": {
        "id": "985jdPC2XJOs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eShpS01j-Jcp"
      },
      "source": [
        "Now it's time to put your model to test by translating your first test file. For this step, the code cell below refers to your *latest model*, which should be saved in the *models* folder in your original Drive folder as **model.fren_step_4000.pt**. The cell also refers to your test dataset, which should be saved in your original Drive folder as `TED2020.de-en.en-filtered.en.subword.test`.\n",
        "\n",
        "In the cell below, we define the `-output` (the translation produced by the model) to be named **translation**. This creates a file in your folder simply called **translation**.\n",
        "\n",
        "You can now simply run the cell below. Your NMT model will then produce a subworded translation of your test dataset. Translating this dataset will take some time. The translation output will be printed during the process."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translation Explained"
      ],
      "metadata": {
        "id": "UjWyB2xzXFMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a closer look at the translation options available in the code cell below:\n",
        "* `-model` – Refers to the last model checkpoint name. You can try testing the quality of multiple checkpoints.\n",
        "* `-src` – Refers to the source file: the subworded test dataset.\n",
        "* `-output` – Refers to the new translation output file; this can be named as required (we call it *translation*).\n",
        "* `-gpu` – Is set to 0, meaning that you actually use one GPU.\n",
        "* `-min_length` – [optional] To avoid empty translations, we set this value to 2.\n",
        "* `-verbose` – [optional] Prints the translations during the process. You could delete `-verbose` if you don't want to see the translation below.\n",
        "\n",
        "You can refer to the [OpenNMT-py translation options](https://opennmt.net/OpenNMT-py/options/translate.html) for more details."
      ],
      "metadata": {
        "id": "ReuPgLtUTswE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translating"
      ],
      "metadata": {
        "id": "ySrP4cHUXCON"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbQEGTj4TybH"
      },
      "outputs": [],
      "source": [
        "# Translate the subworded source file of the test dataset\n",
        "!onmt_translate -model models/model.fren_step_4000.pt -src TED2020.de-en.en-filtered.en.subword.test -output translation -gpu 0 --min_length 2 --verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking the Translation File\n",
        "\n",
        "In case you deleted `-verbose` above, you can check the first 5 lines (or more if you change the value in the first line of code below) of your translation here. `translation` in the cell below refers to your translation file as saved during the step above. If you have changed the name of your translation file, this needs to be changed in the cell below as well. Otherwise, simply run the cell below to print the first 5 lines of your (subworded) translation (don't expect a DeepL-level translation quality; remember that we are training a very small model with a standard parameter set here). You can also re-load your Drive folder and the full translation file created above should have been saved there."
      ],
      "metadata": {
        "id": "IgDM19mBSrru"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHYihrgfIrIO",
        "outputId": "8fd4a202-b13e-4372-8607-e81c81231cc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁Aber ▁es ▁bleibt ▁so ▁viel ▁übrig , ▁von ▁den ▁anderen ▁ 9 , 9 ▁Prozent ▁der ▁Dinge ▁zu ▁lernen , ▁die ▁jemals ▁gelebt ▁haben .\n",
            "▁Aber ▁mit ▁Hilfe ▁von ▁Technik ▁und ▁ Einfallsreichtum ▁wuchs ▁die ▁Vietnamesen ▁auf .\n",
            "▁So ▁sehr ▁schnell ▁-- ▁ungefähr ▁sechs ▁Wochen ▁in ▁diese ▁Forschung ▁-- ▁Ich ▁habe ▁diese ▁komplett ▁b röcke lt er , ▁dass ▁ich ▁die ▁Verbindung ▁absolut ▁auf ▁eine ▁Art ▁und ▁Weise , ▁die ▁ich ▁nicht ▁verstand ▁oder ▁nie ▁hatte .\n",
            "▁\" Der ▁warme ▁Winde ▁können ▁dich ▁nicht ▁berühren .\"\n",
            "▁Amerikaner ▁erkannten ▁seine ▁Leistung ▁und ▁riefen ▁den ▁Pfad : ▁\" Eine s ▁der ▁größten ▁ Errungenschaften ▁des ▁ 2 0 . ▁Jahrhunderts .\"\n"
          ]
        }
      ],
      "source": [
        "!head -n 5 translation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desubwording your Translation\n",
        "\n",
        "Now you have to desubword your translation file for further evaluation. This will remove the underscores visible in the subworded translation output above and combine individual subwords such as *_v* and *erfassungswidrig* into full words such as *verfassungswidrig*. In order to desubword your translation, we need to take two important steps: 1. connect this notebook to the [DataLitMT Github Repository](https://github.com/ITMK/DataLitMT), and 2. refer to the **subword models** (specifically *target.model*) trained in the previous data preparation task. Check to see in which folder you have saved these models because you will need to access them here.\n",
        "\n",
        "**Note**: If you do not have the saved subword models available, scroll up to the beginning of this notebook to the *Optional – Accessing Data* section. You can download the TED data zip file which also contains the subword source and target models. You can upload the subworded target file into your Google Drive folder and then run the cells below. This step is also explained in the tutorial video.\n",
        "\n",
        "Let's first connect this notebook to the GitHub repository by simply running the code cell below."
      ],
      "metadata": {
        "id": "d8wHuLI3Shob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the DataLitMT GitHub\n",
        "!git clone https://github.com/ITMK/DataLitMT.git"
      ],
      "metadata": {
        "id": "amMHMRoyEzSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now install the latest version of [SentencePiece](https://aclanthology.org/D18-2012/) (a language-independent subword tokenizer and detokenizer for neural network-based text processing, such as NMT). Simply run the cell below."
      ],
      "metadata": {
        "id": "AAbd_E8eE5wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If needed install/update SentencePiece\n",
        "!pip3 install --upgrade -q sentencepiece"
      ],
      "metadata": {
        "id": "DlNc9vUYFk01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you know where you saved your **subword target.model** from the Data Planning and Collection task, you can desubword your translation. In the cell below, we need to access three files:\n",
        "\n",
        "1. The desubwording python file from the DataLit<sup>MT</sup> GitHub repository accessed by `DataLitMT/data-preparation/desubword.py` (no need to change anything here),\n",
        "2.   Your subword *target.model* (from the previous task) – if this is saved in a different folder, you need to change the cell below to `YOUR_FOLDER/target.model` to access it,\n",
        "3.   The translation that you just created above – If you saved it under a different name, you need to change the name `translation` below."
      ],
      "metadata": {
        "id": "9XejO0XnFnxc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRsJm6UET2C_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b9c9fc-bbf2-41e8-994e-45493952833b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: translation.desubword\n"
          ]
        }
      ],
      "source": [
        "# Desubword the translation file\n",
        "!python3 DataLitMT/learning_resources/data_planning_and_collection/desubword.py target.model translation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The desubworded translation file will have been saved automatically to your working folder as `translation.desubworded`, so check your Drive folder for this file. Again, if you re-named your translation file, check for the file `your_name.desubworded`.\n",
        "\n",
        "You can also check the first 5 lines of the subworded file by running the cell below. If needed, change the name of your translation file."
      ],
      "metadata": {
        "id": "FlUdJNMoG7n8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai4RhhGaKBp1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee21e1b2-0c96-4974-8842-7a2d56121ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aber es bleibt so viel übrig, von den anderen 9,9 Prozent der Dinge zu lernen, die jemals gelebt haben.\n",
            "Aber mit Hilfe von Technik und Einfallsreichtum wuchs die Vietnamesen auf.\n",
            "So sehr schnell -- ungefähr sechs Wochen in diese Forschung -- Ich habe diese komplett bröckelter, dass ich die Verbindung absolut auf eine Art und Weise, die ich nicht verstand oder nie hatte.\n",
            "\"Der warme Winde können dich nicht berühren.\"\n",
            "Amerikaner erkannten seine Leistung und riefen den Pfad: \"Eines der größten Errungenschaften des 20. Jahrhunderts.\"\n"
          ]
        }
      ],
      "source": [
        "# Check the first 5 lines of the desubworded translation file\n",
        "!head -n 5 translation.desubword"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare this desubworded translation output to the subworded translation output above to see which changes were made through this desubwording step.\n",
        "\n",
        "Now you can also **desubword the reference dataset**: the German test dataset you have split from the original dataset during the Data Planning and Collection task. It should be saved as `TED2020.de-en.de-filtered.de.subword.test` and can now be used as a reference against which you can compare the German translation.\n",
        "\n",
        "Reference data is needed to perform a manual or automatic quality evaluation of an NMT model by analysing the output by analysing the model output. Automatic quality evaluation is further explained in our respective [Basic Level](https://colab.research.google.com/drive/1UgsqgN-6yfDESU7Geei4RXzJShEQNViZ?usp=sharing\n",
        ") and [Advanced Level](https://colab.research.google.com/drive/19a896dbRBVtJmqA6JIFBU7bUiASfAo6V?usp=sharing) notebooks.\n",
        "\n",
        "Note: If you have trained the NMT model from German to English or for a different language combination, make sure you refer to the correct test data as the reference below."
      ],
      "metadata": {
        "id": "LOeAuJ2cHY-X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOUWB4r3OFOV",
        "outputId": "669ec779-0198-45e0-cff3-83d2ae2ddf62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: TED2020.de-en.de-filtered.de.subword.test.desubword\n"
          ]
        }
      ],
      "source": [
        "# Desubword the target file (reference) of the test dataset\n",
        "!python3 DataLitMT/learning_resources/data_planning_and_collection/desubword.py target.model TED2020.de-en.de-filtered.de.subword.test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Equally, the desubworded reference file should now have been saved automatically to your Drive folder as `TED2020.de-en.de-filtered.de.subword.test.desubworded` – Check your folder for this file. Of course, you can also change the name of this file if later you make sure to refer to the correct file names when, for example, calculating automatic quality scores for your translation output.\n",
        "Run the cell below to check the first 5 lines of the desubworded reference (test) set.\n"
      ],
      "metadata": {
        "id": "KiG3YMleIRM1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jULN0MwOFeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e90241-c508-4447-d1ee-cb3a3e3740c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aber es gibt noch viele andere Quellen, z.B. die 99,9 Prozent der Lebewesen, die auf der Erde heimisch waren.\n",
            "Aber mit Baukunst und Einfallsreichtum wurde der Pfad erweitert und verbessert.\n",
            "Sehr bald -- bereits nach etwa sechs Wochen Forschung -- traf ich auf diese unbenannte Sache, die Verbindung gänzlich entschlüsselte, auf eine Weise, die ich nicht verstand oder nie zuvor gesehen hatte.\n",
            "\"Die heißen Winde können dir nichts antun.\"\n",
            "Amerika erkannte diese Leistung und nannte es: \"Die größte Leistung in militärischer Konstruktion im 20.\n"
          ]
        }
      ],
      "source": [
        "# Check the first 5 lines of the desubworded reference\n",
        "!head -n 5 TED2020.de-en.de-filtered.de.subword.test.desubword"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick Evaluation\n",
        "\n",
        "In this section, we will calculate the **BLEU** score by [Papineni et al. (2002)](https://www.aclweb.org/anthology/P02-1040.pdf) in its **sacreBLEU implementation** ([Post 2018](https://aclanthology.org/W18-6319/)) (for the translation (`translation`) by referring to the reference data (the test dataset `TED2020.de-en.de-filtered.de.subword.test.desubworded`).\n",
        "\n",
        "For this, you will need to install the sacreBLEU package by simply running the cell below."
      ],
      "metadata": {
        "id": "A9Gyp0HsTGmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and import (sacre)BLEU functions\n",
        "!pip install sacrebleu\n",
        "import sacrebleu\n",
        "from sacrebleu.metrics import BLEU"
      ],
      "metadata": {
        "id": "2gdtxypUTIAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can calculate the BLEU score for your translation by running the cell below. Once again, if you have changed the name of your files, please adapt the file names accordingly in the cell below."
      ],
      "metadata": {
        "id": "r_MtqeHuToSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate a sacreBLEU score for your translation\n",
        "!sacrebleu TED2020.de-en.de-filtered.de.subword.test.desubword -i translation.desubword -m bleu --score-only --width 2"
      ],
      "metadata": {
        "id": "6Znk65TMTKZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba615fab-61fa-457b-c3a9-10dcdf99ed00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23.60\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLEU scores are interpreted on a scale between 0 and 100. The closer the score is to 100, the higher the quality of the translation. Again, don't expect a very high score here, as we've trained only a small NMT model using a standard parameter set.\n",
        "\n",
        "There is a range of automatic metrics, for MT quality evaluation. Have a look at our [notebook on automatic MT quality evaluation](https://colab.research.google.com/drive/19xcHt9oLcvcSLGOepayTOIO_wkSPSZmG?usp=sharing) for a more detailed introduction to the topic. You can also use the code in our quality evaluation notebook to calculate different scores for your translation output produced in the present notebook."
      ],
      "metadata": {
        "id": "UiL28rOVT0fq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! You have now successfully trained an NMT model from scratch using your previously prepared datasets, and you have created a translation using this NMT model. Finally, you have performed a quick quality evaluation by calculating a BLEU score for your translation output. Welcome to the MT community! 😀"
      ],
      "metadata": {
        "id": "VXASz0MBqRDZ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}