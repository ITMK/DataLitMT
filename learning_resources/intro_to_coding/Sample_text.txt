The professional translation industry has been subject to processes of extensive digitalisation and datafication in recent years.
The digitalisation of the translation profession is characterised by the continuous evolution of existing translation technologies or the development of new translation technologies geared at supporting or optimising all phases of the professional translation process (cf Sandrini, 2017).
The datafication of translation, on the other hand, is characterised by the accumulation and process integration of large-scale digital translation resources such as translation memories or multilingual text corpora (ibid.) as well as by processes of gathering metadata (e.g., data on translation speed and quality or on post-editing productivity) and using such metadata for algorithmic decision making (such as translation job assignments) (cf. Garcia, 2017).
A prime example of the interplay of digitalisation and datafication in a translation technology context is the data-driven paradigm of neural machine translation (NMT), where an MT system based on current innovations in artificial intelligence (AI) and natural language processing (NLP) is trained with large-scale and high-quality translation corpora and learns to translate previously unseen texts based on this training data.
Due to its relatively high output quality, NMT is increasingly being employed in professional translation production networks.
The high relevance and multifaceted impact of NMT in the professional translation process requires translators to develop an adequate degree of machine translation literacy (Bowker & Ciro, 2019).
MT literacy, which will be discussed in more detail in section 3 below, can be understood as a digital literacy, which O’Brien & Ehrensberger-Dow (2020, p. 147) define as “a set of skills and competencies needed to find, interpret, evaluate and handle digital information”.
In addition to this increasing relevance of MT literacy on the part of professional translators, another digital literacy, i.e., data literacy, is gaining importance – both in professional contexts and in wider society (see section 4).
In this regard, Ridsdale et al. (2015, p. 8) observe that “[t]the society of the 21st century is arguably a data rich one” and that “[a]ny country that does not have a technology and data savvy citizenry will be left behind both socially and economically” (ibid.).
There is an immediate link between data literacy and machine translation literacy, which, in the neural paradigm, is concerned with MT systems the performance of which depends on their training with high-quality translation data (see above).
In other words, machine translation literacy in the age of NMT includes various components of data literacy, as will be discussed further in section 4.
Translation didactics, which has generally recognised the important role of NMT in the translation profession and the corresponding need to educate students accordingly (see, for example, Massey & Ehrensberger-Dow, 2017; EMT, 2017; Mellinger, 2017), also has to reflect and incorporate this data dimension of modern MT systems and translator training institutions have to find ways to incorporate suitable didactic resources into their curricula.